{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7aa2744",
   "metadata": {},
   "source": [
    "# Checkpoint 1 — Demo Notebook\n",
    "\n",
    "Interactive walkthrough of the full pipeline:\n",
    "1. Inspect sampled dataset\n",
    "2. Visualise triplets\n",
    "3. Load embeddings\n",
    "4. Train baseline (or show pre-trained results)\n",
    "5. Analyse prompt–failure correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69aa7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'scripts'))\n",
    "\n",
    "from utils.io import load_jsonl\n",
    "from utils.schema import ADHERENCE_LABELS, ERROR_TYPES, LabelRecord\n",
    "from utils.prompt_features import extract_prompt_features, PROMPT_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5264af",
   "metadata": {},
   "source": [
    "## 1. Inspect sampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a40435",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = PROJECT_ROOT / 'data' / 'sample'\n",
    "\n",
    "meta = load_jsonl(DATA_DIR / 'metadata.jsonl')\n",
    "print(f'Total samples: {len(meta)}')\n",
    "if meta:\n",
    "    print('\\nFirst record:')\n",
    "    print(json.dumps(meta[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9d747",
   "metadata": {},
   "source": [
    "## 2. Visualise a few triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01757505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_triplet(rec, data_dir):\n",
    "    orig = Image.open(data_dir / rec['orig_path'])\n",
    "    edit = Image.open(data_dir / rec['edited_path'])\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(orig); axes[0].set_title('Original'); axes[0].axis('off')\n",
    "    axes[1].imshow(edit); axes[1].set_title('Edited');   axes[1].axis('off')\n",
    "    fig.suptitle(f'Prompt: {rec[\"prompt\"]}', fontsize=11, y=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if meta:\n",
    "    for rec in meta[:3]:\n",
    "        show_triplet(rec, DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb8c3b",
   "metadata": {},
   "source": [
    "## 3. Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a27a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_path = DATA_DIR / 'embeddings.npz'\n",
    "if emb_path.exists():\n",
    "    npz = np.load(str(emb_path), allow_pickle=True)\n",
    "    print('Embedding arrays:', list(npz.keys()))\n",
    "    print('emb_orig shape:', npz['emb_orig'].shape)\n",
    "    print('emb_edit shape:', npz['emb_edit'].shape)\n",
    "    print('emb_text shape:', npz['emb_text'].shape)\n",
    "else:\n",
    "    print('No embeddings found. Run: python scripts/extract_embeddings.py --data data/sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f551983",
   "metadata": {},
   "source": [
    "## 4. Labels + baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PATH = PROJECT_ROOT / 'data' / 'annotations' / 'labels.jsonl'\n",
    "labels = load_jsonl(LABELS_PATH)\n",
    "print(f'Labels collected: {len(labels)}')\n",
    "\n",
    "if labels:\n",
    "    df_labels = pd.DataFrame(labels)\n",
    "    print('\\nAdherence distribution:')\n",
    "    print(df_labels['adherence'].value_counts())\n",
    "\n",
    "metrics_path = PROJECT_ROOT / 'runs' / 'baseline' / 'metrics.json'\n",
    "if metrics_path.exists():\n",
    "    metrics = json.loads(metrics_path.read_text())\n",
    "    print('\\n--- Baseline metrics ---')\n",
    "    print(json.dumps(metrics, indent=2))\n",
    "\n",
    "cm_path = PROJECT_ROOT / 'runs' / 'baseline' / 'confusion_matrix.png'\n",
    "if cm_path.exists():\n",
    "    img = Image.open(cm_path)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.imshow(img); plt.axis('off'); plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca9c8d",
   "metadata": {},
   "source": [
    "## 5. Prompt–failure analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0481140",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_dir = PROJECT_ROOT / 'runs' / 'baseline' / 'analysis'\n",
    "\n",
    "corr_path = analysis_dir / 'correlations.csv'\n",
    "if corr_path.exists():\n",
    "    corr = pd.read_csv(corr_path, index_col=0)\n",
    "    print('Correlation matrix (prompt features × failure indicators):')\n",
    "    display(corr.style.background_gradient(cmap='RdBu_r', vmin=-1, vmax=1))\n",
    "\n",
    "for png_name in ['heatmap_correlations.png', 'error_type_frequency.png',\n",
    "                  'wordcount_by_adherence.png', 'adherence_distribution.png']:\n",
    "    p = analysis_dir / png_name\n",
    "    if p.exists():\n",
    "        img = Image.open(p)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(img); plt.axis('off'); plt.title(png_name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d14b12",
   "metadata": {},
   "source": [
    "## 6. Cross-lingual readiness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ab66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text_encoder import load_translations\n",
    "\n",
    "trans = load_translations(DATA_DIR / 'translations.csv')\n",
    "if trans:\n",
    "    print(f'Translations loaded for {len(trans)} samples:')\n",
    "    for sid, langs in list(trans.items())[:5]:\n",
    "        print(f'  {sid}: {langs}')\n",
    "else:\n",
    "    print('No translations.csv found (optional for checkpoint 1).')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
